{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Project Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from: https://github.com/bitcraze/crazyflie-lib-python/blob/master/examples/autonomousSequence.py\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CrazyFlie imports:\n",
    "\n",
    "import cflib.crtp\n",
    "from cflib.crazyflie import Crazyflie\n",
    "from cflib.crazyflie.log import LogConfig\n",
    "from cflib.crazyflie.syncCrazyflie import SyncCrazyflie\n",
    "from cflib.crazyflie.syncLogger import SyncLogger\n",
    "from cflib.positioning.position_hl_commander import PositionHlCommander\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding Box "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box:\n",
    "    def __init__(self, x, y, yaw=0, length=2.54, width=2.28):\n",
    "        self.origin = (x, y)\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.starting_yaw = yaw\n",
    "        self.path = [(x, y)]\n",
    "        # Calculate the x and y of the goal\n",
    "        \n",
    "        # Convert yaw from degrees to radians for trigonometric calculations\n",
    "        yaw_rad = np.radians(yaw)\n",
    "        # ----- getting goal -----\n",
    "        goal_x = x + length * np.cos(yaw_rad)\n",
    "        goal_y = y + length * np.sin(yaw_rad)\n",
    "        goal = (goal_x, goal_y)\n",
    "        self.goal = goal\n",
    "\n",
    "        # ----- get prime bookfinding position -----\n",
    "        self.prime = (goal_x, goal_y)\n",
    "        \n",
    "        # ----- get left wall -----\n",
    "        left_yaw_rad = yaw_rad - np.pi / 2  # Subtract 90 degrees to get the left direction\n",
    "        \n",
    "        # Calculate the points for the left wall\n",
    "        # The first point is near the origin\n",
    "        left_wall_x1 = x + width/2 * np.cos(left_yaw_rad)\n",
    "        left_wall_y1 = y + width/2 * np.sin(left_yaw_rad)\n",
    "\n",
    "        # The second point is near the goal\n",
    "        left_wall_x2 = goal[0] + width/2 * np.cos(left_yaw_rad)\n",
    "        left_wall_y2 = goal[1] + width/2 * np.sin(left_yaw_rad)\n",
    "        self.left_wall = [(left_wall_x1, left_wall_y1), (left_wall_x2, left_wall_y2)]\n",
    "        \n",
    "        # ----- get right wall -----\n",
    "        right_yaw_rad = yaw_rad + np.pi / 2\n",
    "\n",
    "        # Calculate the points for the right wall\n",
    "        # The first point is near the origin\n",
    "        right_wall_x1 = x + width/2 * np.cos(right_yaw_rad)\n",
    "        right_wall_y1 = y + width/2 * np.sin(right_yaw_rad)\n",
    "\n",
    "        # The second point is near the goal\n",
    "        right_wall_x2 = goal[0] + width/2 * np.cos(right_yaw_rad)\n",
    "        right_wall_y2 = goal[1] + width/2 * np.sin(right_yaw_rad)\n",
    "        self.right_wall = [(right_wall_x1, right_wall_y1), (right_wall_x2, right_wall_y2)]\n",
    "\n",
    "        \n",
    "    def get_distance_between_walls(self, x, y):\n",
    "        # Return a value between -1 and 1 that represents distance between the walls\n",
    "        # -1 means the drone is on the left wall, 1 means the drone is on the right wall\n",
    "        # Calculate the shortest distance from the point to the left and right walls\n",
    "        left_wall_distance = abs(y - self.left_wall[0][1])\n",
    "        \n",
    "        normalized_distance = (2*(left_wall_distance / self.width)) - 1\n",
    "        return normalized_distance\n",
    "    \n",
    "    def show_pos(self, x, y):\n",
    "        # Plot the position of the drone within the box, as well as the origin and goal\n",
    "        if self.path[-1][0] != x or self.path[-1][1] != y:\n",
    "            self.path.append((x, y))\n",
    "        # Plot the path\n",
    "        plt.plot(*zip(*self.path), 'p-')\n",
    "        plt.plot(x, y, 'ro')\n",
    "        plt.plot(self.origin[0], self.origin[1], 'bo')\n",
    "        plt.plot(self.goal[0], self.goal[1], 'go')\n",
    "        plt.plot([self.origin[0], self.goal[0]], [self.origin[1], self.goal[1]], 'g--')\n",
    "        plt.plot([self.left_wall[0][0], self.left_wall[1][0]], [self.left_wall[0][1], self.left_wall[1][1]], 'b--')\n",
    "        plt.plot([self.right_wall[0][0], self.right_wall[1][0]], [self.right_wall[0][1], self.right_wall[1][1]], 'b--')\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine direction of least obstacles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def smart_which_way(left_fov, middle_fov, right_fov, x, y, box):\n",
    "    # alpha = how much to favor going forward (>1)\n",
    "    alpha = 1.1\n",
    "    # beta = how much to punish going towards near wall (<1)\n",
    "    beta = 0.6\n",
    "\n",
    "    area = middle_fov.shape[0]*middle_fov.shape[1]\n",
    "    left_score = area - np.count_nonzero(left_fov)\n",
    "    middle_score = area - np.count_nonzero(middle_fov)\n",
    "    right_score = area - np.count_nonzero(right_fov)\n",
    "    print(f'SCORES: [{left_score}, {middle_score}, {right_score}]')\n",
    "    \n",
    "    middle_score *= alpha\n",
    "\n",
    "    # Punish going towards the near wall\n",
    "    dist = box.get_distance_between_walls(x, y)\n",
    "    print(f'DISTANCE: {dist}')\n",
    "\n",
    "    if dist > 0.5:\n",
    "        left_score *= beta\n",
    "    elif dist < -0.85:\n",
    "        right_score *= beta\n",
    "\n",
    "    if dist > 0.6:\n",
    "        if middle_score > 25000 and right_score > 25000:\n",
    "            return 'nne'\n",
    "    elif dist < -0.9:\n",
    "        if middle_score > 25000 and left_score > 25000:\n",
    "            return 'nnw'\n",
    "    \n",
    "    print(f'RESULT: [{left_score}, {middle_score}, {right_score}]')\n",
    "    if middle_score < 15000 or right_score < 12000 or left_score < 12000:\n",
    "        if middle_score > 25000:\n",
    "            return 'forward'\n",
    "        if left_score >= right_score:\n",
    "            return 'scoot left'\n",
    "        else:\n",
    "            return 'scoot right'\n",
    "    if middle_score >= right_score and middle_score >= left_score:\n",
    "        return 'forward'\n",
    "    elif right_score > left_score and right_score > middle_score:\n",
    "        return 'right'\n",
    "    else:\n",
    "        return 'left'\n",
    "\n",
    "def which_way_book(mask):\n",
    "    height, width = mask.shape\n",
    "    left_mask = mask[:, :width//3]\n",
    "    middle_mask = mask[:, width//3:2*width//3]\n",
    "    right_mask = mask[:, 2*width//3:]\n",
    "\n",
    "    left_pixels = np.count_nonzero(left_mask)\n",
    "    middle_pixels = np.count_nonzero(middle_mask)\n",
    "    right_pixels = np.count_nonzero(right_mask)\n",
    "    \n",
    "    print(left_pixels, middle_pixels, right_pixels)\n",
    "\n",
    "    if middle_pixels > left_pixels and middle_pixels > right_pixels and middle_pixels > 0.6 * width * height:\n",
    "        return 'land'\n",
    "    # if the left pixels is within 30% of right pixels, then we're centered\n",
    "    if abs(left_pixels - right_pixels) <= 0.30 * right_pixels and middle_pixels > left_pixels and middle_pixels > right_pixels:\n",
    "        # if the middle is 90 % full\n",
    "        print(middle_pixels / (width * height / 3) * 100, \"%\")\n",
    "        if middle_pixels / (width * height / 3) > 0.175:\n",
    "            return 'land'\n",
    "        else:\n",
    "            # return 'scoot forward'\n",
    "            return 'scoot forward'\n",
    "    elif left_pixels < right_pixels:\n",
    "        return 'scoot right'\n",
    "    else:\n",
    "        return 'scoot left'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_nee(cf, current_x, current_y, duration=8):\n",
    "    dx, dy = 0.23, -0.3\n",
    "    for _ in range(int(duration)):\n",
    "        cf.commander.send_hover_setpoint(dx, dy, 0, 0.9)\n",
    "        time.sleep(0.1)\n",
    "    return current_x + dx*0.75, current_y + dy * 0.9\n",
    "\n",
    "def move_nww(cf, current_x, current_y, duration=8):\n",
    "    dx, dy = 0.23, 0.3\n",
    "    for _ in range(int(duration)):\n",
    "        cf.commander.send_hover_setpoint(dx, dy, 0, 0.9)\n",
    "        time.sleep(0.1)\n",
    "    return current_x + dx*0.75, current_y + dy * 0.9\n",
    "\n",
    "def move_nne(cf, current_x, current_y, duration=8):\n",
    "    dx, dy = 0.3, -0.2\n",
    "    for _ in range(int(duration)):\n",
    "        cf.commander.send_hover_setpoint(dx, dy, 0, 0.9)\n",
    "        time.sleep(0.1)\n",
    "    return current_x + dx*0.75, current_y + dy\n",
    "\n",
    "def move_nnw(cf, current_x, current_y, duration=8):\n",
    "    dx, dy = 0.3, 0.2\n",
    "    for _ in range(int(duration)):\n",
    "        cf.commander.send_hover_setpoint(dx, dy, 0, 0.9)\n",
    "        time.sleep(0.1)\n",
    "    return current_x + dx*0.75, current_y + dy\n",
    "\n",
    "def move_n(cf, current_x, current_y, duration=8):\n",
    "    dx, dy = 0.30, 0\n",
    "    for _ in range(int(duration)):\n",
    "        cf.commander.send_hover_setpoint(dx, dy, 0, 0.9)\n",
    "        time.sleep(0.1)\n",
    "    return current_x + dx*0.75, current_y + dy\n",
    "\n",
    "def move_to_prime(cf, current_x, current_y, box, duration=30):\n",
    "    dx = box.prime[0] - current_x\n",
    "    dy = box.prime[1] - current_y\n",
    "    duration = np.sqrt(dx**2 + dy**2) * 15\n",
    "    for _ in range(int(duration)):\n",
    "        cf.commander.send_hover_setpoint(dx, dy, 0, 0.9)\n",
    "        time.sleep(0.1)\n",
    "    return box.prime[0], box.prime[1]\n",
    "\n",
    "\n",
    "def scoot_e(cf, current_x, current_y, duration=5):\n",
    "    dx, dy = 0, -0.16\n",
    "    for _ in range(int(duration)):\n",
    "        cf.commander.send_hover_setpoint(dx, dy, 0, 0.9)\n",
    "        time.sleep(0.1)\n",
    "    return current_x + dx*0.75, current_y + dy*0.9\n",
    "\n",
    "def scoot_w(cf, current_x, current_y, duration=5):\n",
    "    dx, dy = 0, 0.16\n",
    "    for _ in range(int(duration)):\n",
    "        cf.commander.send_hover_setpoint(dx, dy, 0, 0.9)\n",
    "        time.sleep(0.1)\n",
    "    return current_x + dx*0.75, current_y + dy*0.9\n",
    "\n",
    "def scoot_n(cf, current_x, current_y, duration=6):\n",
    "    dx, dy = 0.2, 0\n",
    "    for _ in range(int(duration)):\n",
    "        cf.commander.send_hover_setpoint(dx, dy, 0, 0.9)\n",
    "        time.sleep(0.1)\n",
    "    return current_x + dx*0.75, current_y + dy, False\n",
    "    \n",
    "\n",
    "def land_forward(cf, current_x, current_y, duration=6):\n",
    "    # TODO: Let use velocities to set it down and slightly forward\n",
    "    print(\"Landing forward\")\n",
    "    return current_x, current_y\n",
    "\n",
    "\n",
    "# Get the current crazyflie position:\n",
    "def position_estimate(scf):\n",
    "#     log_config = LogConfig(name='Kalman Variance', period_in_ms=500)\n",
    "#     log_config.add_variable('kalman.varPX', 'float')\n",
    "#     log_config.add_variable('kalman.varPY', 'float')\n",
    "#     log_config.add_variable('kalman.varPZ', 'float')\n",
    "\n",
    "#     with SyncLogger(scf, log_config) as logger:\n",
    "#         for log_entry in logger:\n",
    "#             data = log_entry[1]\n",
    "#             x = data['kalman.varPX']\n",
    "#             y = data['kalman.varPY']\n",
    "#             z = data['kalman.varPZ']\n",
    "    x, y, z = 0, 0, 0\n",
    "    print(x, y, z)\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "# Set the built-in PID controller:\n",
    "def set_PID_controller(cf):\n",
    "    # Set the PID Controller:\n",
    "    print('Initializing PID Controller')\n",
    "    cf.param.set_value('stabilizer.controller', '1')\n",
    "    cf.param.set_value('kalman.resetEstimation', '1')\n",
    "    time.sleep(0.1)\n",
    "    cf.param.set_value('kalman.resetEstimation', '0')\n",
    "    time.sleep(2)\n",
    "    return\n",
    "\n",
    "\n",
    "# Ascend and hover at 1m:\n",
    "def ascend_and_hover(cf):\n",
    "    # Ascend:\n",
    "    for y in range(5):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, y / 10)\n",
    "        time.sleep(0.1)\n",
    "    # Hover at 0.5 meters:\n",
    "    for _ in range(20):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 0.5)\n",
    "        time.sleep(0.1)\n",
    "    return\n",
    "\n",
    "\n",
    "# Sort through contours in the image\n",
    "def findGreatesContour(contours):\n",
    "    largest_area = 0\n",
    "    largest_contour_index = -1\n",
    "    i = 0\n",
    "    total_contours = len(contours)\n",
    "\n",
    "    while i < total_contours:\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            largest_contour_index = i\n",
    "        i += 1\n",
    "\n",
    "    #print(largest_area)\n",
    "\n",
    "    return largest_area, largest_contour_index\n",
    "\n",
    "\n",
    "# Find contours in the image\n",
    "def check_contours(frame):\n",
    "\n",
    "    print('Checking image:')\n",
    "\n",
    "    # These define the upper and lower HSV for the red obstacles.\n",
    "    # Note that the red color wraps around 180, so there are two intervals.\n",
    "    # Tuning of these values will vary depending on the camera.\n",
    "    lb1 = (145, 35, 75)\n",
    "    ub1 = (180, 255, 255)\n",
    "    lb2 = (0, 75, 75)\n",
    "    ub2 = (20, 255, 255)\n",
    "\n",
    "    # Perform contour detection on the input frame.\n",
    "    hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsv2 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute mask of red obstacles in either color range.\n",
    "    mask1 = cv2.inRange(hsv1, lb1, ub1)\n",
    "    mask2 = cv2.inRange(hsv2, lb2, ub2)\n",
    "    # Combine the masks.\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Use the OpenCV findContours function.\n",
    "    # Note that there are three outputs, but we discard the first one.\n",
    "    _, contours, hierarchy = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    largest_area, largest_contour_index = findGreatesContour(contours)\n",
    "\n",
    "    print(largest_area)\n",
    "\n",
    "    if largest_area > 100:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Follow the setpoint sequence trajectory:\n",
    "def adjust_position(cf, current_y):\n",
    "\n",
    "    print('Adjusting position')\n",
    "\n",
    "    steps_per_meter = int(10)\n",
    "    # Set the number here (the iterations of the for-loop) to the number of side steps.\n",
    "    # You may choose to tune the number and size of the steps.\n",
    "    for i in range(3): \n",
    "        current_y = current_y - 1.0/float(steps_per_meter)\n",
    "        position = [0, current_y, 0.5, 0.0]\n",
    "\n",
    "        print('Setting position {}'.format(position))\n",
    "        for i in range(10):\n",
    "            cf.commander.send_position_setpoint(position[0],\n",
    "                                                position[1],\n",
    "                                                position[2],\n",
    "                                                position[3])\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    cf.commander.send_stop_setpoint()\n",
    "    # Make sure that the last packet leaves before the link is closed.\n",
    "    # The message queue is not flushed before closing.\n",
    "    time.sleep(0.1)\n",
    "    return current_y\n",
    "\n",
    "\n",
    "# Hover, descend, and stop all motion:\n",
    "def hover_and_descend(cf):\n",
    "    print('Descending:')\n",
    "    # Hover at 0.5 meters:\n",
    "    for _ in range(20):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 0.9)\n",
    "        time.sleep(0.1)\n",
    "    # Descend:\n",
    "    for y in range(10):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, (20-2*y) / 25)\n",
    "        time.sleep(0.1)\n",
    "    # Stop all motion:\n",
    "    for i in range(10):\n",
    "        cf.commander.send_stop_setpoint()\n",
    "        time.sleep(0.1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll do k means if this other heuristic approach doesnt work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_number = 16\n",
    "\n",
    "# Possibly try 0, 1, 2 ...\n",
    "camera = 1\n",
    "\n",
    "\n",
    "\n",
    "# states:\n",
    "OBSTACLE_DETECTING = 0\n",
    "AVOIDING = 1\n",
    "BOOK_FINDING = 2\n",
    "BOOK_FOLLOWING = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning interfaces for Crazyflies...\n",
      "Crazyflies found:\n",
      "radio://0/16/2M\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n",
      "wrong cam\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(camera)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(cap\u001b[38;5;241m.\u001b[39misOpened()):\n\u001b[0;32m---> 69\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrong cam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "hover_setpoints = {\n",
    "        OBSTACLE_DETECTING: 0.9,\n",
    "        AVOIDING: 0.9,\n",
    "        BOOK_FINDING: 0.9,\n",
    "        BOOK_FOLLOWING: 0.9,\n",
    "        None: 0.9\n",
    "    }\n",
    "\n",
    "def send_hover_command(cf, state):\n",
    "    while True:\n",
    "        if should_hover:\n",
    "            cf.commander.send_hover_setpoint(0, 0, 0, hover_setpoints[state])\n",
    "        time.sleep(0.1)\n",
    "\n",
    "\n",
    "# flag\n",
    "should_hover = False\n",
    "\n",
    "\n",
    "# Set the URI the Crazyflie will connect to\n",
    "uri = f'radio://0/{group_number}/2M'\n",
    "\n",
    "\n",
    "\n",
    "# Initialize all the CrazyFlie drivers:\n",
    "cflib.crtp.init_drivers(enable_debug_driver=False)\n",
    "\n",
    "# Scan for Crazyflies in range of the antenna:\n",
    "print('Scanning interfaces for Crazyflies...')\n",
    "available = cflib.crtp.scan_interfaces()\n",
    "\n",
    "# List local CrazyFlie devices:\n",
    "print('Crazyflies found:')\n",
    "for i in available:\n",
    "    print(i[0])\n",
    "\n",
    "# Check that CrazyFlie devices are available:\n",
    "if len(available) == 0:\n",
    "    print('No Crazyflies found, cannot run example')\n",
    "else:\n",
    "    ## Ascent to hover; run the sequence; then descend from hover:\n",
    "    # Use the CrazyFlie corresponding to team number:\n",
    "    with SyncCrazyflie(uri, cf=Crazyflie(rw_cache='./cache')) as scf:\n",
    "        # Get the Crazyflie class instance:\n",
    "        cf = scf.cf\n",
    "\n",
    "        state = OBSTACLE_DETECTING\n",
    "        \n",
    "        # Create hover thread\n",
    "        hover_thread = threading.Thread(target=send_hover_command, args=(cf, state,))\n",
    "        hover_thread.daemon = True\n",
    "        hover_thread.start()\n",
    "        \n",
    "        current_x, current_y = 0.0, 0.0\n",
    "\n",
    "        # Initialize and ascend:\n",
    "        t = time.time()\n",
    "        elapsed = time.time() - t\n",
    "        ascended_bool = 0\n",
    "        \n",
    "        frames = []\n",
    "        box = None\n",
    "\n",
    "        cap = cv2.VideoCapture(camera)\n",
    "        while(cap.isOpened()):\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if frame.shape[0] > 600:\n",
    "                print('wrong cam')\n",
    "                camera = (camera + 1) % 2\n",
    "                continue\n",
    "\n",
    "            elapsed = time.time() - t\n",
    "            if(elapsed > 3.0):\n",
    "\n",
    "\n",
    "                if ret:\n",
    "                    cv2.imshow('frame',frame)\n",
    "\n",
    "                    if(ascended_bool==0):\n",
    "                        set_PID_controller(cf)\n",
    "                        ascend_and_hover(cf)\n",
    "                        should_hover=True\n",
    "                        ascended_bool = 1\n",
    "                        x, y, yaw = 0, 0, 0\n",
    "                        box = Box(x, y, yaw)\n",
    "                    else:\n",
    "                        pass\n",
    "            if(elapsed > 8.0):\n",
    "\n",
    "                if state == OBSTACLE_DETECTING:\n",
    "                    should_hover = True\n",
    "                    frames.append(frame)\n",
    "\n",
    "                    if len(frames) >= 70:\n",
    "                        print('COMPUTING')\n",
    "                        # Compute the median frame\n",
    "                        frames = frames[30:]\n",
    "                        frames.sort(key=lambda x: np.count_nonzero(x))\n",
    "                        frames = frames[10:]\n",
    "                        median_frame = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
    "                        frame = median_frame\n",
    "\n",
    "                        # These define the upper and lower HSV for the red obstacles.\n",
    "                        # Note that the red color wraps around 180, so there are two intervals.\n",
    "                        # Tuning of these values will vary depending on the camera.\n",
    "                        lb1 = (145, 35, 75)\n",
    "                        ub1 = (180, 255, 255)\n",
    "                        lb2 = (0, 75, 75)\n",
    "                        ub2 = (20, 255, 255)\n",
    "\n",
    "                        # Perform contour detection on the input frame.\n",
    "                        hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "                        hsv2 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "                        # Compute mask of red obstacles in either color range.\n",
    "                        mask1 = cv2.inRange(hsv1, lb1, ub1)\n",
    "                        mask2 = cv2.inRange(hsv2, lb2, ub2)\n",
    "                        # Combine the masks.\n",
    "                        mask = cv2.bitwise_or(mask1, mask2)\n",
    "                        mask = mask[frame.shape[0]//2-70:frame.shape[0]//2+70,:] # crop to 200 tall from center\n",
    "\n",
    "                        # Divide the FOV into three parts: left, middle, right\n",
    "                        fov_third = mask.shape[1] // 3\n",
    "                        left_fov = mask[:, :fov_third]\n",
    "                        middle_fov = mask[:, fov_third:2*fov_third]\n",
    "                        right_fov = mask[:, 2*fov_third:]\n",
    "\n",
    "                        direction = smart_which_way(left_fov, middle_fov, right_fov, current_x, current_y, box)\n",
    "                        box.show_pos(current_x, current_y)\n",
    "\n",
    "                        # Switch to scanning mode\n",
    "                        state = AVOIDING\n",
    "                        frames = []\n",
    "\n",
    "                elif state == AVOIDING:\n",
    "                    should_hover = False\n",
    "                    print(f\"moving {direction}!\")\n",
    "                    # Perform moving operations\n",
    "                    if direction == 'left':\n",
    "                        current_x, current_y = move_nww(cf, current_x, current_y)\n",
    "                    elif direction == 'right':\n",
    "                        current_x, current_y = move_nee(cf, current_x, current_y)\n",
    "                    elif direction == 'forward':\n",
    "                        current_x, current_y = move_n(cf, current_x, current_y)\n",
    "                    elif direction == 'scoot left':\n",
    "                        current_x, current_y = scoot_w(cf, current_x, current_y)\n",
    "                    elif direction == 'scoot right':\n",
    "                        current_x, current_y = scoot_e(cf, current_x, current_y)\n",
    "                    elif direction == 'nne':\n",
    "                        current_x, current_y = move_nne(cf, current_x, current_y)\n",
    "                    elif direction == 'nnw':\n",
    "                        current_x, current_y = move_nnw(cf, current_x, current_y)\n",
    "                    print('done moving.')\n",
    "                    frames = []\n",
    "\n",
    "                    # Switch to scanning mode\n",
    "                    state = OBSTACLE_DETECTING\n",
    "\n",
    "                elif state == BOOK_FINDING:\n",
    "                    should_hover = True\n",
    "                    # Perform book finding operations\n",
    "\n",
    "                    frames.append(frame)\n",
    "\n",
    "                    if len(frames) >= 60:\n",
    "                        print('COMPUTING')\n",
    "                        # Compute the median frame\n",
    "                        frames = frames[10:]\n",
    "                        frames.sort(key=lambda x: np.count_nonzero(x))\n",
    "                        frames = frames[10:40]\n",
    "                        median_frame = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
    "\n",
    "                        # These define the upper and lower HSV for the blue obstacles.\n",
    "                        # Tuning of these values will vary depending on the camera.\n",
    "                        lb1 = (110, 140, 80)\n",
    "                        ub1 = (140, 255, 255)\n",
    "\n",
    "                        # Perform contour detection on the input frame.\n",
    "                        hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "                        # Compute mask of blue obstacles\n",
    "                        mask = cv2.inRange(hsv1, lb1, ub1)\n",
    "\n",
    "                        mask = mask[frame.shape[0]//2-50:frame.shape[0]//2+50,:] # crop\n",
    "\n",
    "                        # Divide FOV into five parts\n",
    "                        book_direction = which_way_book(mask)\n",
    "\n",
    "                        box.show_pos(current_x, current_y)\n",
    "\n",
    "                        # Switch to scanning mode\n",
    "                        state = BOOK_FOLLOWING\n",
    "                        frames = []\n",
    "\n",
    "\n",
    "                elif state == BOOK_FOLLOWING:\n",
    "                    should_hover = False\n",
    "                    print(f\"moving {book_direction}!\")\n",
    "                    # Perform moving operations\n",
    "                    if book_direction == 'scoot left':\n",
    "                        current_x, current_y = scoot_w(cf, current_x, current_y)\n",
    "                    elif book_direction == 'scoot right':\n",
    "                        current_x, current_y = scoot_e(cf, current_x, current_y)\n",
    "                    elif book_direction == 'land':\n",
    "                        should_hover = False\n",
    "                        print(\"landing.\")\n",
    "                        break\n",
    "                    else:\n",
    "                        current_x, current_y, is_done = scoot_n(cf, current_x, current_y)\n",
    "                        if is_done:\n",
    "                            print(\"landing.\")\n",
    "                            break\n",
    "                    print('done moving.')\n",
    "                    frames = []\n",
    "\n",
    "                    # Switch to scanning mode\n",
    "                    state = BOOK_FINDING\n",
    "                    should_hover = True\n",
    "            \n",
    "            if state != BOOK_FINDING and state != BOOK_FOLLOWING and box is not None and current_x > box.goal[0]:\n",
    "                # move to prime book-finding position\n",
    "                print(\"moving to prime book-finding position.\")\n",
    "                current_x, current_y = move_to_prime(cf, current_x, current_y, box)\n",
    "                box.show_pos(current_x, current_y)\n",
    "                \n",
    "                frames = []\n",
    "                state = BOOK_FINDING\n",
    "            \n",
    "                # print(\"landing.\")\n",
    "                # should_hover = False\n",
    "                # break\n",
    "\n",
    "        cap.release()\n",
    "        \n",
    "        print('elapsed: ', elapsed)\n",
    "\n",
    "        # Descend and stop all motion:\n",
    "        hover_and_descend(cf)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
